{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of P23458_V3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboagyeso/v3_code/blob/master/Copy_of_Copy_of_Copy_of_P23458_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_QFqo42aiX",
        "colab_type": "code",
        "outputId": "cf4cfbaa-8668-4090-cc0c-528396e42ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Embedding, Conv1D, MaxPooling1D, GRU\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import LSTM\n",
        "import numpy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import random \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "maxlen = 100\n",
        "batch_size = 128\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_training/v3/P23458.csv\", delimiter=\",\")\n",
        "#X_train = dataset.iloc[:,0:1].values\n",
        "#y_train = dataset.iloc[:,1:2].values\n",
        "X_train = dataset[['smiles']].values\n",
        "y_train = dataset[['pAc']].values\n",
        "\n",
        "for p in range (X_train.shape[0]):\n",
        "  s = X_train[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_train[p,0] = s\n",
        "X_train = X_train[:,0]  \n",
        "#y_train = y_train[:,0]\n",
        "X_train = X_train.tolist()\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=100)\n",
        "print(X_train)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0 ...  1  1 13]\n",
            " [ 0  0  0 ...  4 10  3]\n",
            " [ 0  0  0 ...  1  1  3]\n",
            " ...\n",
            " [ 0  0  0 ...  1  3  5]\n",
            " [ 0  0  0 ...  3  5  5]\n",
            " [ 0  0  0 ...  1  3  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAGViFDk5r1j",
        "colab_type": "code",
        "outputId": "f3480e0d-aa78-4b29-d3b2-e0b1f0a95efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_validation/smilesP23458.csv\", delimiter=\",\")\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "X_test = dataset[['smiles']].values\n",
        "y_test = dataset[['pAc']].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "for p in range (X_test.shape[0]):\n",
        "  s = X_test[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_test[p,0] = s\n",
        "X_test = X_test[:,0]  \n",
        "#y_test = y_test[:,0]\n",
        "X_test = X_test.tolist()\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen=100)\n",
        "#print(X_test)\n",
        "#print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(100, 128, input_length=100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18480/18480 [==============================] - 21s 1ms/step - loss: 4.3773\n",
            "Epoch 2/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 1.1932\n",
            "Epoch 3/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 1.1543\n",
            "Epoch 4/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 1.1333\n",
            "Epoch 5/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 1.0071\n",
            "Epoch 6/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.8075\n",
            "Epoch 7/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.7775\n",
            "Epoch 8/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.8361\n",
            "Epoch 9/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.7481\n",
            "Epoch 10/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.7398\n",
            "Epoch 11/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.7261\n",
            "Epoch 12/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.7102\n",
            "Epoch 13/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.7047\n",
            "Epoch 14/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.6958\n",
            "Epoch 15/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.6796\n",
            "Epoch 16/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.6756\n",
            "Epoch 17/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.6570\n",
            "Epoch 18/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.6616\n",
            "Epoch 19/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.6496\n",
            "Epoch 20/20\n",
            "18480/18480 [==============================] - 20s 1ms/step - loss: 0.6452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdba0d94b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QojRQg6i4Kfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "f4e1927b-ef73-4056-a35d-c2cc33437820"
      },
      "source": [
        "score = model.evaluate(X_test, y_test,\n",
        "                            batch_size=128)\n",
        "print('Test score:', score)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2_score = r2_score(y_test, predictions)\n",
        "\n",
        "print(str(mae)+\"\\t\"+str(mse)+\"\\t\"+str(r2_score))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131/131 [==============================] - 0s 2ms/step\n",
            "Test score: 0.5061159383022148\n",
            "0.5654450699027257\t0.5061159469964808\t0.5657592046416682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WYlIvMH4KTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPbT3cy4J60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}