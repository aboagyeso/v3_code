{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of P15056_V3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboagyeso/v3_code/blob/master/Copy_of_Copy_of_Copy_of_P15056_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_QFqo42aiX",
        "colab_type": "code",
        "outputId": "dfc08879-3e63-442f-8978-a03baea3b37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Embedding, Conv1D, MaxPooling1D, GRU\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import LSTM\n",
        "import numpy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import random \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "maxlen = 100\n",
        "batch_size = 128\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_training/v3/P15056.csv\", delimiter=\",\")\n",
        "#X_train = dataset.iloc[:,0:1].values\n",
        "#y_train = dataset.iloc[:,1:2].values\n",
        "X_train = dataset[['smiles']].values\n",
        "y_train = dataset[['pAc']].values\n",
        "\n",
        "for p in range (X_train.shape[0]):\n",
        "  s = X_train[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_train[p,0] = s\n",
        "X_train = X_train[:,0]  \n",
        "#y_train = y_train[:,0]\n",
        "X_train = X_train.tolist()\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=100)\n",
        "print(X_train)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0 ...  2  6  1]\n",
            " [ 0  0  0 ...  4 10  3]\n",
            " [ 0  0  0 ...  3  1  4]\n",
            " ...\n",
            " [ 0  0  0 ...  1  1  4]\n",
            " [ 0  0  0 ...  6  1  4]\n",
            " [ 0  0  0 ...  4  2  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAGViFDk5r1j",
        "colab_type": "code",
        "outputId": "a087fc1d-60b5-45b7-b37f-aa8bd0d35c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_validation/smilesP15056.csv\", delimiter=\",\")\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "X_test = dataset[['smiles']].values\n",
        "y_test = dataset[['pAc']].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "for p in range (X_test.shape[0]):\n",
        "  s = X_test[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_test[p,0] = s\n",
        "X_test = X_test[:,0]  \n",
        "#y_test = y_test[:,0]\n",
        "X_test = X_test.tolist()\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen=100)\n",
        "#print(X_test)\n",
        "#print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(100, 128, input_length=100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 13:43:15.986222 140336095459200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 13:43:16.019861 140336095459200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 13:43:16.027803 140336095459200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 13:43:16.366657 140336095459200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 13:43:16.636220 140336095459200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0727 13:43:17.364107 140336095459200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0727 13:43:17.519308 140336095459200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25440/25440 [==============================] - 72s 3ms/step - loss: 4.1299\n",
            "Epoch 2/20\n",
            "25440/25440 [==============================] - 73s 3ms/step - loss: 1.5864\n",
            "Epoch 3/20\n",
            "25440/25440 [==============================] - 173s 7ms/step - loss: 1.5769\n",
            "Epoch 4/20\n",
            "25440/25440 [==============================] - 214s 8ms/step - loss: 1.5711\n",
            "Epoch 5/20\n",
            "25440/25440 [==============================] - 215s 8ms/step - loss: 1.5577\n",
            "Epoch 6/20\n",
            "25440/25440 [==============================] - 211s 8ms/step - loss: 1.2260\n",
            "Epoch 7/20\n",
            "25440/25440 [==============================] - 214s 8ms/step - loss: 1.1077\n",
            "Epoch 8/20\n",
            "25440/25440 [==============================] - 211s 8ms/step - loss: 1.0981\n",
            "Epoch 9/20\n",
            "25440/25440 [==============================] - 211s 8ms/step - loss: 1.0955\n",
            "Epoch 10/20\n",
            "25440/25440 [==============================] - 213s 8ms/step - loss: 1.0704\n",
            "Epoch 11/20\n",
            "25440/25440 [==============================] - 211s 8ms/step - loss: 1.0664\n",
            "Epoch 12/20\n",
            "25440/25440 [==============================] - 212s 8ms/step - loss: 1.0557\n",
            "Epoch 13/20\n",
            "25440/25440 [==============================] - 209s 8ms/step - loss: 1.0369\n",
            "Epoch 14/20\n",
            "25440/25440 [==============================] - 209s 8ms/step - loss: 1.0253\n",
            "Epoch 15/20\n",
            "25440/25440 [==============================] - 159s 6ms/step - loss: 0.9901\n",
            "Epoch 16/20\n",
            "25440/25440 [==============================] - 138s 5ms/step - loss: 0.9452\n",
            "Epoch 17/20\n",
            "25440/25440 [==============================] - 115s 5ms/step - loss: 0.9019\n",
            "Epoch 18/20\n",
            "25440/25440 [==============================] - 71s 3ms/step - loss: 0.8526\n",
            "Epoch 19/20\n",
            "25440/25440 [==============================] - 71s 3ms/step - loss: 0.8079\n",
            "Epoch 20/20\n",
            "25440/25440 [==============================] - 71s 3ms/step - loss: 0.7598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa24919c9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QojRQg6i4Kfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "69bba616-5596-49ad-aff9-5a995cb9a669"
      },
      "source": [
        "score = model.evaluate(X_test, y_test,\n",
        "                            batch_size=128)\n",
        "print('Test score:', score)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2_score = r2_score(y_test, predictions)\n",
        "\n",
        "print(str(mae)+\"\\t\"+str(mse)+\"\\t\"+str(r2_score))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "171/171 [==============================] - 0s 2ms/step\n",
            "Test score: 0.6114022526127553\n",
            "0.6100648696514863\t0.6114021313250508\t0.566573075896484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WYlIvMH4KTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPbT3cy4J60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}